# CRAWLER
Crawler for search engine

## Overview ğŸ“‹
The code performs the following functions:

1- Check if every file and folder we need is ready, and prepare them if they are not.

2- Download and store documents.

3- Extract metadata from text files.

5- Repeat the process every minute.

## Running the code ğŸ”§
*Java 17 and json are required to run the code*

Ensure all the files from the repo are present in the same directory.

Open the project in any preferred IDE of your choice and run the Main.java file, on the Crawler_Package foulder.

## Detailed List of Functionalities Implemented âš™ï¸
### In the folder InvertedIndex:

It is similar to the inverted index project made previously in python but now in java.

### In the folder Crawler

### In the folder Crawler_Package

Main module of the project, automates the process to do it every minute

### In the folder Downloader

Download and store the files of the Project Gutenberg collection

### In the folder MetaData_Extractor

Extract metadata from text file and save it in Json format

## Built With ğŸ› ï¸

* [Intellij Idea](https://www.jetbrains.com/es-es/idea/) - The text editor used.
* [Java 17](https://www.oracle.com/java/technologies/javase/jdk17-archive-downloads.html) - The java version used.
## Authors âœ’ï¸
* **Javier GarcÃ­a**
* **JesÃºs Matos**
* **Liam Mahmud**
* **Krish Sadhwani**
